{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob, os\n",
    "import gsw\n",
    "import xarray as xr\n",
    "from scipy.interpolate import RegularGridInterpolator as rgi\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This code is used to interpolate variables onto the particle trajectories. The output of this processing step is saved and used in subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load all particles into a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the folder 'particle_output' can be downloaded from doi:10.6084/m9.figshare.13322435\n",
    "dfdict = {}\n",
    "for d in np.arange(44,63):\n",
    "    conn = sqlite3.connect(\"particle_output/ini_day\"+str(d)+\"_5m_forward.db\")\n",
    "    cur = conn.cursor()\n",
    "    df = pd.read_sql_query(\"select DOY, ID, x, y, z, u, v, w, density, vorticity, PV from particles;\", conn)\n",
    "    df1 = df.pivot(index='DOY', columns='ID')\n",
    "    dfdict['df'+str(d)] = df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute model gradients and interpolate onto particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d0 in np.arange(44,63):\n",
    "    df1 = dfdict['df'+str(d0)]\n",
    "    df1div = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Q1 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Q2 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1nonlin = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1ag = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1wz = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1rx = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1ry = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1rz = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1ml = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1vor2 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1vor3 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    dfML = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    for d in df1.index.values:\n",
    "        day0 = int(np.floor(d*86400/108/100)*100)\n",
    "        day1 = day0+100\n",
    "        dd = np.mod(int(d*86400/108),100)\n",
    "        filename = './../../exp_IRENE_1wiggle_cooled_bottom_friction/full_'+str(day0)+'.cdf'\n",
    "        DS0 = xr.open_dataset(filename)\n",
    "        DS0 = DS0.assign_coords(x = DS0.xc*1000,y = DS0.yc*1000,sigma = DS0.zc[:,1,1])\n",
    "        filename = './../../exp_IRENE_1wiggle_cooled_bottom_friction/full_'+str(day1)+'.cdf'\n",
    "        DS1 = xr.open_dataset(filename)\n",
    "        DS1 = DS1.assign_coords(x = DS1.xc*1000,y = DS1.yc*1000,sigma = DS0.zc[:,1,1])\n",
    "        DS = DS0*(1-dd/100)+DS1*dd/100\n",
    "\n",
    "        rx = DS.rho.differentiate('x')\n",
    "        ry = DS.rho.differentiate('y')\n",
    "        rz = DS.rho.differentiate('sigma')\n",
    "        wx = DS.w.differentiate('x')\n",
    "        wy = DS.w.differentiate('y')\n",
    "        wz = DS.w.differentiate('sigma')\n",
    "        ux = DS.u.differentiate('x')\n",
    "        uy = DS.u.differentiate('y')\n",
    "        uz = DS.u.differentiate('sigma')\n",
    "        vx = DS.v.differentiate('x')\n",
    "        vy = DS.v.differentiate('y')\n",
    "        vz = DS.v.differentiate('sigma')\n",
    "        \n",
    "        px = DS.p.differentiate('x')\n",
    "        pxx = px.differentiate('x')\n",
    "        py = DS.p.differentiate('y')\n",
    "        pyy = py.differentiate('y')\n",
    "        hx = DS.h.differentiate('x')\n",
    "        hxx = hx.differentiate('x')\n",
    "        hy = DS.h.differentiate('y')\n",
    "        hyy = hy.differentiate('y')\n",
    "            \n",
    "        g = 9.81\n",
    "        R0 = 1027\n",
    "        f = gsw.f(36.5)\n",
    "        div = ux+vy\n",
    "        Q1 = -ux*rx*g/R0-vx*ry*g/R0\n",
    "        Q2 = -uy*rx*g/R0-vy*ry*g/R0\n",
    "        nonlin = -(ux**2+vy**2+2*vx*uy+wx*uz+wy*vz)\n",
    "        ag2 = -g*(hxx+hyy)\n",
    "        ag3 = DS.vor*f-(pxx+pyy)/R0\n",
    "        ag = ag2+ag3\n",
    "        vor2 = wy-vz\n",
    "        vor3 = uz-wx\n",
    "        \n",
    "        ML = DS.zc.values\n",
    "        ML[np.where(DS.rho > (DS.rho[-1,:,:]+0.03))] = np.nan\n",
    "        ML = np.nanmin(ML,axis = 0)\n",
    "        \n",
    "        x = xr.DataArray(df1['x'].loc[d,:], dims='ID')\n",
    "        y = xr.DataArray(df1['y'].loc[d,:], dims='ID')\n",
    "        z = xr.DataArray(df1['z'].loc[d,:], dims='ID')\n",
    "        \n",
    "        df1rx.loc[d] = rx.interp(x=x, y=y, sigma = z)\n",
    "        df1ry.loc[d] = ry.interp(x=x, y=y, sigma = z)\n",
    "        df1rz.loc[d] = rz.interp(x=x, y=y, sigma = z)\n",
    "        df1vor2.loc[d] = vor2.interp(x=x, y=y, sigma = z)\n",
    "        df1vor3.loc[d] = vor3.interp(x=x, y=y, sigma = z)\n",
    "        \n",
    "        df1div.loc[d] = div.interp(x=x, y=y, sigma = z)\n",
    "        df1Q1.loc[d] = Q1.interp(x=x, y=y, sigma = z)\n",
    "        df1Q2.loc[d] = Q2.interp(x=x, y=y, sigma = z)\n",
    "        df1nonlin.loc[d] = nonlin.interp(x=x, y=y, sigma = z)\n",
    "        df1ag.loc[d] = ag.interp(x=x, y=y, sigma = z)\n",
    "        df1wz.loc[d] = wz.interp(x=x, y=y, sigma = z)\n",
    "        \n",
    "        MLfunction = rgi((DS.yc*1000,DS.xc*1000),ML,bounds_error = False)\n",
    "        dfML.loc[d] = MLfunction(np.array((y,x)).T)\n",
    "        \n",
    "        DS0.close()\n",
    "        DS1.close()\n",
    "        DS.close()\n",
    "    dfdict['df'+str(d0)+'div'] = df1div\n",
    "    dfdict['df'+str(d0)+'Q1'] = df1Q1\n",
    "    dfdict['df'+str(d0)+'Q2'] = df1Q2\n",
    "    dfdict['df'+str(d0)+'nonlin'] = df1nonlin\n",
    "    dfdict['df'+str(d0)+'ag'] = df1ag\n",
    "    dfdict['df'+str(d0)+'wz'] = df1wz\n",
    "    dfdict['df'+str(d0)+'rx'] = df1rx\n",
    "    dfdict['df'+str(d0)+'ry'] = df1ry\n",
    "    dfdict['df'+str(d0)+'rz'] = df1rz\n",
    "    dfdict['df'+str(d0)+'ml'] = df1ml\n",
    "    dfdict['df'+str(d0)+'vor2'] = df1vor2\n",
    "    dfdict['df'+str(d0)+'vor3'] = df1vor3\n",
    "    dfdict['df'+str(d0)+'ML'] = dfML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the subduction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d0 in np.arange(44,63):\n",
    "    z1 = dfdict['df'+str(d0)]['z']\n",
    "    r1 = dfdict['df'+str(d0)+'rz']\n",
    "    ml = dfdict['df'+str(d0)+'ML']\n",
    "    subducted = (z1.iloc[-1,:] < (ml.iloc[-1,:]-5)) & (z1.iloc[0,:] > ml.iloc[0,:]) & (z1.iloc[-1,:]+5 < -5)\n",
    "    downtime = (z1.loc[:,subducted] < (ml.loc[:,subducted]-5)) & (z1.loc[:,subducted] < -5)\n",
    "    time1 = pd.DataFrame(index=downtime.index, columns=downtime.columns)\n",
    "    for ID in downtime.columns:\n",
    "        time1.loc[:,ID] = downtime.index - downtime.index[downtime.loc[:,ID]][0]\n",
    "    dfdict['time'+str(d0)] = time1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute frontogenesis terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interpolate gradients onto the particles so that we can quantify which frontogenetic terms are important\n",
    "g = 9.81\n",
    "R0 = 1027\n",
    "f = gsw.f(36.9)\n",
    "k = 1\n",
    "v = 1e-5\n",
    "for d0 in np.arange(44,62):\n",
    "    # open particle positions\n",
    "    df1 = dfdict['df'+str(d0)]\n",
    "    # initialize dataframes\n",
    "    df1Q1 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Q2 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Qg1 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Qg2 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Qw = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Qkh = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Qkv = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1div = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    df1Qkh1 = pd.DataFrame(index=df1.index, columns=df1['x'].columns)\n",
    "    for d in df1.index.values:\n",
    "        day0 = int(np.floor(d*86400/108/100)*100)\n",
    "        day1 = day0+100\n",
    "        dd = np.mod(int(d*86400/108),100)\n",
    "        filename = './../../exp_IRENE_1wiggle_cooled_bottom_friction/full_'+str(day0)+'.cdf'\n",
    "        DS0 = xr.open_dataset(filename)\n",
    "        DS0 = DS0.assign_coords(x = DS0.xc*1000,y = DS0.yc*1000,sigma = DS0.zc[:,1,1])\n",
    "        filename = './../../exp_IRENE_1wiggle_cooled_bottom_friction/full_'+str(day1)+'.cdf'\n",
    "        DS1 = xr.open_dataset(filename)\n",
    "        DS1 = DS1.assign_coords(x = DS1.xc*1000,y = DS1.yc*1000,sigma = DS0.zc[:,1,1])\n",
    "        DS = DS0*(1-dd/100)+DS1*dd/100\n",
    "\n",
    "        rx = DS.rho.differentiate('x')\n",
    "        ry = DS.rho.differentiate('y')\n",
    "        rz = DS.rho.differentiate('sigma')\n",
    "        hx = DS.h.differentiate('x')\n",
    "        hy = DS.h.differentiate('y')\n",
    "        \n",
    "        M4 = (rx**2+ry**2)*g**2/R0**2\n",
    "        M4x = M4.differentiate('x')\n",
    "        M4y = M4.differentiate('y')\n",
    "        M4xx = M4x.differentiate('x')\n",
    "        M4yy = M4y.differentiate('y')\n",
    "             \n",
    "        rxx = rx.differentiate('x')\n",
    "        ryy = ry.differentiate('y')\n",
    "        rzz = rz.differentiate('sigma')\n",
    "             \n",
    "        rxxx = rxx.differentiate('x')\n",
    "        ryyx = ryy.differentiate('x')\n",
    "        rzzx = rzz.differentiate('x')\n",
    "             \n",
    "        rxxy = rxx.differentiate('y')\n",
    "        ryyy = ryy.differentiate('y')\n",
    "        rzzy = rzz.differentiate('y')\n",
    "             \n",
    "        ## Calcuate geostrophic velocity\n",
    "        ugeo = xr.DataArray(np.empty((66,322,258)),dims=['sigma','y','x'])\n",
    "        vgeo = xr.DataArray(np.empty((66,322,258)),dims=['sigma','y','x'])\n",
    "        ugeo[-1,:,:] = -g/f*hy\n",
    "        vgeo[-1,:,:] = g/f*hx\n",
    "        for k in np.arange(1,66):\n",
    "            ugz = np.trapz(-ry[k:,:,:]*g/R0/f,DS.zc[k:,:,:],axis = 0)\n",
    "            vgz = np.trapz(rx[k:,:,:]*g/R0/f,DS.zc[k:,:,:],axis = 0)\n",
    "            ugeo[k,:,:] = ugeo[-1,:,:]+ugz\n",
    "            vgeo[k,:,:] = vgeo[-1,:,:]+vgz\n",
    "        \n",
    "        ugeo = ugeo.assign_coords(x = DS0.xc*1000,y = DS0.yc*1000,sigma = DS0.zc[:,1,1])\n",
    "        vgeo = vgeo.assign_coords(x = DS0.xc*1000,y = DS0.yc*1000,sigma = DS0.zc[:,1,1])\n",
    "        ua = DS.u-ugeo\n",
    "        va = DS.v-vgeo\n",
    "            \n",
    "        ux = ua.differentiate('x')\n",
    "        uy = ua.differentiate('y')\n",
    "        vx = va.differentiate('x')\n",
    "        vy = va.differentiate('y')\n",
    "            \n",
    "        wx = DS.w.differentiate('x')\n",
    "        wy = DS.w.differentiate('y')\n",
    "             \n",
    "        ugx = ugeo.differentiate('x')\n",
    "        ugy = ugeo.differentiate('y')\n",
    "        vgx = vgeo.differentiate('x')\n",
    "        vgy = vgeo.differentiate('y')\n",
    "            \n",
    "        Q1 = -ux*rx*g/R0-vx*ry*g/R0\n",
    "        Q2 = -uy*rx*g/R0-vy*ry*g/R0\n",
    "        Qg1 = -ugx*rx*g/R0-vgx*ry*g/R0\n",
    "        Qg2 = -ugy*rx*g/R0-vgy*ry*g/R0\n",
    "            \n",
    "        Qw = wx*rz*g/R0*rx*g/R0+wy*rz*g/R0*ry*g/R0\n",
    "        Qkh = k*g/R0*(rxxx+ryyx)*g/R0*rx+k*g/R0*(rxxy+ryyy)*g/R0*ry\n",
    "        Qkv = v*g/R0*rzzx*g/R0*rx+v*g/R0*rzzy*g/R0*ry\n",
    "        Qkh1 = k*(M4xx+M4yy)\n",
    "            \n",
    "        div = ux+vy\n",
    "            \n",
    "        x = xr.DataArray(df1['x'].loc[d,:], dims='ID')\n",
    "        y = xr.DataArray(df1['y'].loc[d,:], dims='ID')\n",
    "        z = xr.DataArray(df1['z'].loc[d,:], dims='ID')\n",
    "             \n",
    "        df1Q1.loc[d] = Q1.interp(x=x, y=y, sigma = z)\n",
    "        df1Q2.loc[d] = Q2.interp(x=x, y=y, sigma = z)\n",
    "        df1Qg1.loc[d] = Qg1.interp(x=x, y=y, sigma = z)\n",
    "        df1Qg2.loc[d] = Qg2.interp(x=x, y=y, sigma = z)\n",
    "        df1Qw.loc[d] = Qw.interp(x=x, y=y, sigma = z)\n",
    "        df1Qkh.loc[d] = Qkh.interp(x=x, y=y, sigma = z)\n",
    "        df1Qkv.loc[d] = Qkv.interp(x=x, y=y, sigma = z)\n",
    "        df1div.loc[d] = div.interp(x=x, y=y, sigma = z)\n",
    "        df1Qkh1.loc[d] = Qkh1.interp(x=x, y=y, sigma = z)\n",
    "     \n",
    "        DS0.close()\n",
    "        DS1.close()\n",
    "    dfdict['df'+str(d0)+'Q1'] = df1Q1\n",
    "    dfdict['df'+str(d0)+'Q2'] = df1Q2\n",
    "    dfdict['df'+str(d0)+'Qg1'] = df1Qg1\n",
    "    dfdict['df'+str(d0)+'Qg2'] = df1Qg2\n",
    "    dfdict['df'+str(d0)+'Qw'] = df1Qw\n",
    "    dfdict['df'+str(d0)+'Qkh'] = df1Qkh\n",
    "    dfdict['df'+str(d0)+'Qkv'] = df1Qkv\n",
    "    dfdict['df'+str(d0)+'div'] = div\n",
    "    dfdict['df'+str(d0)+'Qkh1'] = df1Qkh1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save particle dictionary with variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"particles_with_gradients.pkl\",\"wb\")\n",
    "pickle.dump(dfdict,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
